{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import utils, corpora, models, similarities\n",
    "from simserver import SessionServer\n",
    "import simserver\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "import psycopg2\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import preprocess_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to database\n",
    "dbname = 'podcast'\n",
    "username = 'lindsay'\n",
    "con = psycopg2.connect(database = dbname, user = username)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download data from database\n",
    "query = \"SELECT id, collection_id, summary, episode_descriptions, episode_names FROM podcast\"\n",
    "cursor.execute(query, con)\n",
    "query_results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# put into dataframe, concatenate text and remove non-alphanumeric characters for each podcast\n",
    "query_df = pd.DataFrame({'id' : [x[0] for x in query_results],\n",
    "                         'collection_id' : [x[1] for x in query_results],\n",
    "                         'summary' : [x[2] for x in query_results],\n",
    "                         'episode_descriptions' : [x[3] for x in query_results],\n",
    "                         'episode_names' : [x[4] for x in query_results]})\n",
    "\n",
    "podcast_text = pd.DataFrame(columns=['id', 'collection_id', 'text'])\n",
    "for ind, row in tqdm(query_df.iterrows(), total = query_df.shape[0]):\n",
    "    # concatenate\n",
    "    text = ' '.join([row['summary'], row['episode_descriptions'], row['episode_names']])\n",
    "    \n",
    "    # remove non-alphanumeric, non-space\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    \n",
    "    podcast_text = podcast_text.append(pd.DataFrame({'id' : [row['id']],\n",
    "                                                     'collection_id': [row['collection_id']],\n",
    "                                                    'text' : [text]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server = SessionServer('/tmp/simserver/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del(podcast_text['collection_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert text to pre-processed tokens\n",
    "podcast_text['tokens'] = [preprocess_text.preprocess_text(x) for x in podcast_text['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18521</td>\n",
       "      <td>A weekly conversation about whats new in The N...</td>\n",
       "      <td>[weekli, convers, new, new, yorker, orson, wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18522</td>\n",
       "      <td>Welcome to Superhero News Your source for the ...</td>\n",
       "      <td>[welcom, superhero, news, sourc, latest, movi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12350</td>\n",
       "      <td>Insurance news interviews rating announcements...</td>\n",
       "      <td>[insur, news, interview, rate, announc, insur,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12351</td>\n",
       "      <td>The Amovetv crew talk video games eSports a lo...</td>\n",
       "      <td>[amovetv, crew, talk, video, game, esport, lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18373</td>\n",
       "      <td>Assorted stories from WMEHFM A look at whats b...</td>\n",
       "      <td>[assort, stori, wmehfm, look, done, larg, smal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  18521  A weekly conversation about whats new in The N...   \n",
       "0  18522  Welcome to Superhero News Your source for the ...   \n",
       "0  12350  Insurance news interviews rating announcements...   \n",
       "0  12351  The Amovetv crew talk video games eSports a lo...   \n",
       "0  18373  Assorted stories from WMEHFM A look at whats b...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [weekli, convers, new, new, yorker, orson, wel...  \n",
       "0  [welcom, superhero, news, sourc, latest, movi,...  \n",
       "0  [insur, news, interview, rate, announc, insur,...  \n",
       "0  [amovetv, crew, talk, video, game, esport, lot...  \n",
       "0  [assort, stori, wmehfm, look, done, larg, smal...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(podcast_text['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [{'id' : int(x['id']),\n",
    "           'tokens' : x['tokens']}\n",
    "         for ind, x in podcast_text.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# upload corpus to server\n",
    "utils.upload_chunked(server, corpus, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:sqlitedict:failed to delete /var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldict713110\n",
      "Traceback (most recent call last):\n",
      "  File \"//anaconda/lib/python2.7/site-packages/sqlitedict.py\", line 283, in terminate\n",
      "    os.remove(self.filename)\n",
      "OSError: [Errno 2] No such file or directory: '/var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldict713110'\n",
      "ERROR:sqlitedict:failed to delete /var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldict628ff3\n",
      "Traceback (most recent call last):\n",
      "  File \"//anaconda/lib/python2.7/site-packages/sqlitedict.py\", line 283, in terminate\n",
      "    os.remove(self.filename)\n",
      "OSError: [Errno 2] No such file or directory: '/var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldict628ff3'\n",
      "ERROR:sqlitedict:failed to delete /var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldict13c128\n",
      "Traceback (most recent call last):\n",
      "  File \"//anaconda/lib/python2.7/site-packages/sqlitedict.py\", line 283, in terminate\n",
      "    os.remove(self.filename)\n",
      "OSError: [Errno 2] No such file or directory: '/var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldict13c128'\n"
     ]
    }
   ],
   "source": [
    "# train server (uses LSI and 100 TF-IDF topics)\n",
    "server.train(corpus, method='lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:sqlitedict:failed to delete /var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldict65a1d0\n",
      "Traceback (most recent call last):\n",
      "  File \"//anaconda/lib/python2.7/site-packages/sqlitedict.py\", line 283, in terminate\n",
      "    os.remove(self.filename)\n",
      "OSError: [Errno 2] No such file or directory: '/var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldict65a1d0'\n",
      "ERROR:sqlitedict:failed to delete /var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldictb903d2\n",
      "Traceback (most recent call last):\n",
      "  File \"//anaconda/lib/python2.7/site-packages/sqlitedict.py\", line 283, in terminate\n",
      "    os.remove(self.filename)\n",
      "OSError: [Errno 2] No such file or directory: '/var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldictb903d2'\n",
      "ERROR:sqlitedict:failed to delete /var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldicta90943\n",
      "Traceback (most recent call last):\n",
      "  File \"//anaconda/lib/python2.7/site-packages/sqlitedict.py\", line 283, in terminate\n",
      "    os.remove(self.filename)\n",
      "OSError: [Errno 2] No such file or directory: '/var/folders/hg/kw83c_j57xqd055hr739mhvm0000gn/T/sqldicta90943'\n"
     ]
    }
   ],
   "source": [
    "# index documents we trained on\n",
    "server.index(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# query for similar documents to existing podcast\n",
    "sim_result = server.find_similar('12352')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# query for similar results to keyword\n",
    "doc = {'tokens' : preprocess_text.preprocess_text('cats')}\n",
    "key_result = server.find_similar(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
