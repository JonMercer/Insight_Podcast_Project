{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = pd.read_pickle('gensim/preprocessed_text.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove words that only appear once in all documents\n",
    "frequency = defaultdict(int)\n",
    "for text in documents['text']:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "        \n",
    "documents['text'] = [[token for token in text if frequency[token] > 1]\n",
    "              for text in documents['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# still some web address tokens, so remove tokens containing 'http' or 'www'\n",
    "documents_no_web = pd.DataFrame(columns=documents.columns)\n",
    "for ind, row in documents.iterrows():\n",
    "    text = row['text']\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if re.search(r'http', word):\n",
    "            continue\n",
    "        if re.search(r'www', word):\n",
    "            continue\n",
    "        new_text.append(word)\n",
    "    row['text'] = new_text\n",
    "    documents_no_web = documents_no_web.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save re-pre-processed text\n",
    "documents_no_web.to_pickle('gensim/preprocessed_text_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(174016 unique tokens: [u'fawn', u'sticman', u'denber', u'lowkramen', u'fawk']...)\n"
     ]
    }
   ],
   "source": [
    "# create dictionary\n",
    "dictionary = corpora.Dictionary(documents_no_web['text'])\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(51857 unique tokens: [u'fawn', u'fawl', u'circuitri', u'fawk', u'damfunk']...)\n"
     ]
    }
   ],
   "source": [
    "# filter extremes in dictionary\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
    "print dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save\n",
    "dictionary.save('gensim/dictionary.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert documents to bag of words\n",
    "corpus = [dictionary.doc2bow(text) for text in documents_no_web['text']]\n",
    "corpora.MmCorpus.serialize('gensim/corpus.mm', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform to tfidf\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "corpora.MmCorpus.serialize('gensim/corpus_tfidf.mm', corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 s, sys: 1.1 s, total: 25.9 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "# lsi model on tfidf\n",
    "%time lsi = models.lsimodel.LsiModel(corpus_tfidf, num_topics = 100, id2word=dictionary)\n",
    "lsi.save('gensim/model.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    }
   ],
   "source": [
    "# calculate similarities\n",
    "index = similarities.MatrixSimilarity(lsi[corpus_tfidf])\n",
    "index.save('gensim/tfidf_lsi_similarities.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
