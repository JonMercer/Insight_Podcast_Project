{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "import urllib2\n",
    "import unidecode\n",
    "import tqdm\n",
    "import pickle\n",
    "import pycurl\n",
    "import time\n",
    "import guess_language\n",
    "import psycopg2\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_itunes_charts_ids(url):\n",
    "    r = requests.get(url)\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c)\n",
    "    samples = soup.findAll(\"p\", \"buy\")\n",
    "    \n",
    "    ids = []\n",
    "    for s in samples:\n",
    "        s = str(s.contents[0])\n",
    "        ids.append(re.findall(r'/id([\\d]+)', s)[0])\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape_urls = ['http://www.itunescharts.net/us/charts/podcasts/2016/01/29',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/comedy/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/tv-film/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/technology/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/sport/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/games-hobbies/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/arts/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/music/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/religion-spirituality/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/science-medicine/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ids = []\n",
    "for url in scrape_urls:\n",
    "    ids = get_itunes_charts_ids(url)\n",
    "    all_ids = all_ids + ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add purrrcast\n",
    "all_ids = all_ids + ['1041016803']\n",
    "\n",
    "# remove duplicates\n",
    "all_ids = list(set(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will store pycurl output\n",
    "class Test:\n",
    "   def __init__(self):\n",
    "       self.contents = ''\n",
    "\n",
    "   def body_callback(self, buf):\n",
    "       self.contents = self.contents + buf\n",
    "        \n",
    "def run_curl(url):\n",
    "    t = Test()\n",
    "    c = pycurl.Curl()\n",
    "    c.setopt(pycurl.URL, url)\n",
    "    c.setopt(pycurl.HTTPHEADER, ['X-Apple-Store-Front: 143441-1,12', 'X-Apple-Tz: 3600'])\n",
    "    c.setopt(pycurl.USERAGENT, 'iTunes/9.2.1 (Macintosh; Intel Mac OS X 10.5.8) AppleWebKit/533.16')\n",
    "    c.setopt(pycurl.SSL_VERIFYHOST, 0)\n",
    "    c.setopt(pycurl.SSL_VERIFYPEER, 0)\n",
    "    c.setopt(pycurl.WRITEFUNCTION, t.body_callback)\n",
    "    c.perform()\n",
    "    return t\n",
    "\n",
    "def clean_description(d):\n",
    "    d = unidecode.unidecode(d)\n",
    "    d = d.replace('\\n', ' ')\n",
    "    if re.findall(r'(.*) brought to you by.*', d):\n",
    "       d = re.sub(r'brought to you by.*', '', d)\n",
    "    if re.search(r'(.*) sponsored by.*', d):\n",
    "       d = re.sub(r'sponsored by.*', '', d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "baseUrl = 'https://itunes.apple.com/us/podcast/id'\n",
    "colNames = ['collectionId', 'podcastSummary', 'episodeNames', 'episodeDescriptions', 'alsoSubscribed']\n",
    "scrapeResults = pd.DataFrame(columns=colNames)\n",
    "\n",
    "for i in tqdm.tqdm(all_ids):\n",
    "    scrapeUrl = baseUrl + str(i)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        try:\n",
    "            newUrl = newUrl[0]\n",
    "            newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(i),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(i),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(i),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the results\n",
    "scrapeResults['episodeDescriptions'] = [unicode(x) for x in scrapeResults['episodeDescriptions']]\n",
    "scrapeResults['episodeNames'] = [unicode(x) for x in scrapeResults['episodeNames']]\n",
    "scrapeResults['podcastSummary'] = [unicode(x) for x in scrapeResults['podcastSummary']]\n",
    "scrapeResults.to_pickle('pkl/itunes_charts_scrape_' + time.strftime(\"%d-%m-%Y\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct iTunes API url\n",
    "id_list = scrapeResults['collectionId'].tolist()\n",
    "id_list = [int(x) for x in id_list]\n",
    "\n",
    "api_base_url = 'https://itunes.apple.com/lookup?id=' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colNames = [u'feedUrl',\n",
    " u'contentAdvisoryRating',\n",
    " u'trackRentalPrice',\n",
    " u'collectionExplicitness',\n",
    " u'releaseDate',\n",
    " u'currency',\n",
    " u'artistId',\n",
    " u'trackPrice',\n",
    " u'trackViewUrl',\n",
    " u'genres',\n",
    " u'collectionName',\n",
    " u'collectionId',\n",
    " u'trackId',\n",
    " u'artworkUrl600',\n",
    " u'collectionViewUrl',\n",
    " u'trackCount',\n",
    " u'primaryGenreName',\n",
    " u'collectionPrice',\n",
    " u'trackCensoredName',\n",
    " u'genreIds',\n",
    " u'trackName',\n",
    " u'artistViewUrl',\n",
    " u'kind',\n",
    " u'collectionHdPrice',\n",
    " u'trackHdRentalPrice',\n",
    " u'wrapperType',\n",
    " u'artworkUrl100',\n",
    " u'collectionCensoredName',\n",
    " u'trackHdPrice',\n",
    " u'radioStationUrl',\n",
    " u'artistName',\n",
    " u'artworkUrl60',\n",
    " u'trackExplicitness',\n",
    " u'artworkUrl30',\n",
    " u'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "api_results = pd.DataFrame(columns=colNames)\n",
    "\n",
    "for i in tqdm.tqdm(id_list):\n",
    "    api_url = api_base_url + str(i)\n",
    "    r = requests.get(api_url)\n",
    "    text = r.text\n",
    "    data = json.loads(text)\n",
    "    thisResult = pd.io.json.json_normalize(data['results'])\n",
    "    api_results = pd.concat([api_results, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge scrape & api results\n",
    "podcastDf = pd.merge(api_results, scrapeResults, how = 'inner', on = 'collectionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to int\n",
    "podcastDf['collectionId'] = [int(x) for x in podcastDf['collectionId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# guess language of summary\n",
    "podcastDf['language'] = [guess_language.guessLanguageName(x) for x in podcastDf['podcastSummary']]\n",
    "podcastDf = podcastDf[podcastDf['language'] == 'English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove mixed alphanumeric\n",
    "    text = re.sub(r\"\"\"(?x) # verbose regex\n",
    "                            \\b    # Start of word\n",
    "                            (?=   # Look ahead to ensure that this word contains...\n",
    "                             \\w*  # (after any number of alphanumeric characters)\n",
    "                             \\d   # ...at least one digit.\n",
    "                            )     # End of lookahead\n",
    "                            \\w+   # Match the alphanumeric word\n",
    "                            \\s*   # Match any following whitespace\"\"\", \n",
    "                             \"\", text)\n",
    "    \n",
    "    # remove urls\n",
    "    text = re.sub(r'\\s([\\S]*.com[\\S]*)\\b', '', text)\n",
    "    text = re.sub(r'\\s([\\S]*.org[\\S]*)\\b', '', text)\n",
    "\n",
    "    \n",
    "    \n",
    "    # remove non-alphanumeric, non-space\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# clean episode data\n",
    "episodeDf = podcastDf[['collectionId','episodeDescriptions', 'episodeNames']]\n",
    "episodeDf['episodeDescriptions'] = [x.split(\"\\',\") for x in episodeDf['episodeDescriptions']]\n",
    "episodeDf['episodeNames'] = [x.split(\"\\',\") for x in episodeDf['episodeNames']]\n",
    "\n",
    "clean_episode_description = []\n",
    "for pod in episodeDf['episodeDescriptions']:\n",
    "    clean_list = []\n",
    "    for ep in pod:\n",
    "        clean_list.append(clean_text(ep))\n",
    "    clean_episode_description.append(clean_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "episodeDf['clean_episode_description'] = clean_episode_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "clean_episode_name = []\n",
    "for pod in episodeDf['episodeNames']:\n",
    "    clean_list = []\n",
    "    for ep in pod:\n",
    "        clean_list.append(clean_text(ep))\n",
    "    clean_episode_name.append(clean_list)\n",
    "episodeDf['clean_episode_name'] = clean_episode_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del episodeDf['episodeDescriptions']\n",
    "del episodeDf['episodeNames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "podcastDf = pd.merge(podcastDf, episodeDf, how = 'inner', on='collectionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean podcast summary\n",
    "podcastDf['podcastSummary'] = [clean_text(x) for x in podcastDf['podcastSummary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save clean data\n",
    "podcastDf.to_pickle('pkl/clean_podcast_data' + time.strftime(\"%d-%m-%Y\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to database\n",
    "dbname = 'podcast'\n",
    "username = 'lindsay'\n",
    "con = psycopg2.connect(database = dbname, user = username)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# upload data to database\n",
    "query_id = \"SELECT id FROM podcast WHERE collection_id = '%s';\"\n",
    "query_update = \"INSERT INTO podcast (artwork_url30, artwork_url60, artwork_url100, artwork_url600, explicit, name, view_url, summary, episode_descriptions, episode_names, collection_id) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) RETURNING id;\"\n",
    "\n",
    "for ind, thisPod in tqdm.tqdm(podcastDf.iterrows(), total=podcastDf.shape[0]):\n",
    "    \n",
    "    # check if in database\n",
    "    cursor.execute(query_id, (thisPod['collectionId'], ))\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    if len(result) == 0:\n",
    "        data = (thisPod['artworkUrl30'], thisPod['artworkUrl60'], thisPod['artworkUrl100'], thisPod['artworkUrl600'], thisPod['contentAdvisoryRating'], thisPod['collectionCensoredName'], thisPod['collectionViewUrl'], thisPod['podcastSummary'], thisPod['clean_episode_description'], thisPod['clean_episode_name'], thisPod['collectionId'])\n",
    "        cursor.execute(query_update, data)\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get back ids\n",
    "query_id = \"SELECT id FROM podcast WHERE collection_id = '%s';\"\n",
    "db_ids = []\n",
    "for ind, thisPod in podcastDf.iterrows():\n",
    "    cursor.execute(query_id, (thisPod['collectionId'], ))\n",
    "    db_ids.append(cursor.fetchall())\n",
    "    \n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_ids = [x[0] for x in db_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_ids = [x[0] for x in db_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "podcastDf['podcast_id'] = db_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 2)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique artists\n",
    "artistDf = podcastDf[['artistName', 'artistViewUrl']]\n",
    "artistDf = artistDf.drop_duplicates()\n",
    "artistDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert artist data into artist table\n",
    "query_artist = \"SELECT id FROM artist WHERE name = %s;\"\n",
    "query_insert = \"INSERT INTO artist (view_url, name) VALUES (%s, %s) RETURNING id;\"\n",
    "artist_id = []\n",
    "for ind, row in artistDf.iterrows():\n",
    "    data = (row['artistName'], )\n",
    "    cursor.execute(query_artist, data)\n",
    "    result = cursor.fetchone()[0]\n",
    "    \n",
    "    if result:\n",
    "        artist_id.append(result)\n",
    "    else:\n",
    "        data = (row['artistViewUrl'], row['artistName'])\n",
    "        cursor.execute(query_insert, data)\n",
    "        artist_id.append(cursor.fetchone()[0])\n",
    "        \n",
    "con.commit()\n",
    "artistDf['artist_id'] = artist_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get unique genres\n",
    "genreDf = podcastDf['genres']\n",
    "genreList = []\n",
    "for row in genreDf:\n",
    "    for genre in row:\n",
    "        genreList.append(genre)\n",
    "genreList = list(set(genreList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert genre data into genre table\n",
    "query_genre = \"SELECT * FROM genre WHERE name = %s;\"\n",
    "query_insert = \"INSERT INTO genre (name) VALUES (%s) RETURNING id;\"\n",
    "genre_id = []\n",
    "for item in genreList:\n",
    "    data = (item, )\n",
    "    cursor.execute(query_genre, data)\n",
    "    result = cursor.fetchone()[0]\n",
    "    if result:\n",
    "        genre_id.append(result)\n",
    "        \n",
    "    else:\n",
    "        cursor.execute(query_insert, data)\n",
    "        genre_id.append(cursor.fetchone()[0])\n",
    "con.commit()\n",
    "genreDf = pd.DataFrame({'name' : genreList,\n",
    "                       'genre_id': genre_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "podcast_artist = pd.merge(podcastDf, artistDf, how = 'inner', on = 'artistName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert artist id into podcast table\n",
    "query = \"UPDATE podcast SET artist_id=(%s) WHERE id = (%s);\"\n",
    "for ind, row in podcast_artist.iterrows():\n",
    "    data = (row['artist_id'], row['podcast_id'])\n",
    "    cursor.execute(query, data)\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "podcast_genre = pd.DataFrame(columns=['podcast_id', 'genre_name'])\n",
    "for ind, row in podcastDf.iterrows():\n",
    "    for genre in row['genres']:\n",
    "        \n",
    "        podcast_genre = podcast_genre.append(pd.DataFrame({'podcast_id' : [row['podcast_id']],\n",
    "                                            'genre_name' : [genre]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "podcast_genre = pd.merge(podcast_genre, genreDf, how = 'inner', left_on='genre_name', right_on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_name</th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arts</td>\n",
       "      <td>18521</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arts</td>\n",
       "      <td>13989</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arts</td>\n",
       "      <td>18523</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arts</td>\n",
       "      <td>18538</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arts</td>\n",
       "      <td>18539</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre_name  podcast_id  genre_id  name\n",
       "0       Arts       18521       205  Arts\n",
       "1       Arts       13989       205  Arts\n",
       "2       Arts       18523       205  Arts\n",
       "3       Arts       18538       205  Arts\n",
       "4       Arts       18539       205  Arts"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert podcast-genre mappings into podcast_has_genre table\n",
    "query = \"INSERT INTO podcast_has_genre (podcast_id, genre_id) VALUES (%s, %s);\"\n",
    "for ind, row in podcast_genre.iterrows():\n",
    "    data = (row['podcast_id'], row['genre_id'])\n",
    "    cursor.execute(query, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_also_subscribed = podcastDf[['podcast_id', 'alsoSubscribed']]\n",
    "also_subscribed = pd.DataFrame(columns = ['podcast_id', 'also_subscribed'])\n",
    "for ind, row in tmp_also_subscribed.iterrows():\n",
    "    for sub in row['alsoSubscribed']:\n",
    "        also_subscribed = also_subscribed.append(pd.DataFrame({'podcast_id' : [row['podcast_id']],\n",
    "                                                              'also_subscribed' : [sub]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "also_subscribed.rename(columns = {'podcast_id':'initial_podcast_id'}, inplace=True)\n",
    "podcastId = podcastDf[['podcast_id', 'collectionId']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "also_subscribed = pd.merge(also_subscribed, podcastId, how = 'inner', left_on='also_subscribed', right_on='collectionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert also_subscribed data\n",
    "query = \"INSERT INTO also_subscribed (initial_podcast, subscribed_podcast) VALUES (%s, %s);\"\n",
    "for ind, row in also_subscribed.iterrows():\n",
    "    data = (row['initial_podcast_id'], row['podcast_id'])\n",
    "    cursor.execute(query, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pkl dfs\n",
    "podcastDf.to_pickle('pkl/podcastDf_with_sql_id' + time.strftime(\"%d-%m-%Y\") + '.pkl')\n",
    "artistDf.to_pickle('pkl/artistDf_with_sql_id.pkl' + time.strftime(\"%d-%m-%Y\") + '.pkl')\n",
    "genreDf.to_pickle('pkl/genreDf_with_sql_id.pkl' + time.strftime(\"%d-%m-%Y\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT id, collection_id, summary, episode_descriptions, episode_names FROM podcast\"\n",
    "cursor.execute(query, con)\n",
    "query_results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_df = pd.DataFrame({'id' : [x[0] for x in query_results],\n",
    "                         'collection_id' : [x[1] for x in query_results],\n",
    "                         'summary' : [x[2] for x in query_results],\n",
    "                         'episode_descriptions' : [x[3] for x in query_results],\n",
    "                         'episode_names' : [x[4] for x in query_results]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate text and remove non-alphanumeric characters for each podcast\n",
    "podcast_text = pd.DataFrame(columns=['id', 'collection_id', 'text', 'language'])\n",
    "for ind, row in query_df.iterrows():\n",
    "    # concatenate\n",
    "    text = ' '.join([row['summary'], row['episode_descriptions'], row['episode_names']])\n",
    "    \n",
    "    # remove non-alphanumeric, non-space\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    \n",
    "    # guess language of text\n",
    "    language = guess_language.guessLanguageName(text)\n",
    "    \n",
    "    podcast_text = podcast_text.append(pd.DataFrame({'id' : [row['id']],\n",
    "                                                     'collection_id': [row['collection_id']],\n",
    "                                                    'text' : [text],\n",
    "                                                    'language' : [language]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126723118</td>\n",
       "      <td>12350</td>\n",
       "      <td>English</td>\n",
       "      <td>Insurance news interviews rating announcements...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>699748055</td>\n",
       "      <td>12351</td>\n",
       "      <td>English</td>\n",
       "      <td>The Amovetv crew talk video games eSports a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258723953</td>\n",
       "      <td>18521</td>\n",
       "      <td>English</td>\n",
       "      <td>A weekly conversation about whats new in The N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>529175048</td>\n",
       "      <td>12357</td>\n",
       "      <td>English</td>\n",
       "      <td>AfricanAmerican Conservatives focuses on topic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290783428</td>\n",
       "      <td>18527</td>\n",
       "      <td>English</td>\n",
       "      <td>Money makes the world go around faster and fas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_id     id language  \\\n",
       "0      126723118  12350  English   \n",
       "0      699748055  12351  English   \n",
       "0      258723953  18521  English   \n",
       "0      529175048  12357  English   \n",
       "0      290783428  18527  English   \n",
       "\n",
       "                                                text  \n",
       "0  Insurance news interviews rating announcements...  \n",
       "0  The Amovetv crew talk video games eSports a lo...  \n",
       "0  A weekly conversation about whats new in The N...  \n",
       "0  AfricanAmerican Conservatives focuses on topic...  \n",
       "0  Money makes the world go around faster and fas...  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# tokenize text\n",
    "tokenized = podcast_text.copy(deep=True)\n",
    "tokenized['text'] = [tokenizer.tokenize(x.lower()) for x in tokenized['text']]\n",
    "\n",
    "# create list of stop words\n",
    "stop = get_stop_words('en')\n",
    "\n",
    "# remove non-alphanumeric, non-space\n",
    "stop = [re.sub(r'([^\\s\\w]|_)+', '', x) for x in stop]\n",
    "\n",
    "# add in custom stop words\n",
    "days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "other = ['nan', 'podcast']\n",
    "\n",
    "[stop.append(unicode(day)) for day in days]\n",
    "[stop.append(unicode(month)) for month in months]\n",
    "[stop.append(unicode(x)) for x in other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop(text, stop):\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word not in stop:\n",
    "            new_text.append(word)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "stopped = tokenized.copy(deep=True)\n",
    "stopped['text'] = [remove_stop(text,stop) for text in stopped['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_list(text, p_stemmer):\n",
    "    new_list = []\n",
    "    for word in text:\n",
    "        new_list.append(p_stemmer.stem(word))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem words\n",
    "p_stemmer = PorterStemmer()\n",
    "stemmed = stopped.copy(deep=True)\n",
    "stemmed['text'] = [stem_list(text, p_stemmer) for text in stemmed['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove tokens containing 'http' or 'www'\n",
    "documents_no_web = pd.DataFrame(columns=stemmed.columns)\n",
    "for ind, row in stemmed.iterrows():\n",
    "    text = row['text']\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if re.search(r'http', word):\n",
    "            continue\n",
    "        if re.search(r'www', word):\n",
    "            continue\n",
    "        new_text.append(word)\n",
    "    row['text'] = new_text\n",
    "    documents_no_web = documents_no_web.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18521</td>\n",
       "      <td>English</td>\n",
       "      <td>[weekli, convers, new, new, yorker, orson, wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18522</td>\n",
       "      <td>English</td>\n",
       "      <td>[welcom, superhero, news, sourc, latest, movi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13989</td>\n",
       "      <td>English</td>\n",
       "      <td>[death, sex, amp, money, big, question, hard, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18523</td>\n",
       "      <td>English</td>\n",
       "      <td>[snap, judgment, storytel, beat, mix, real, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18524</td>\n",
       "      <td>English</td>\n",
       "      <td>[frontlin, present, audio, version, select, fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id language                                               text\n",
       "0  18521  English  [weekli, convers, new, new, yorker, orson, wel...\n",
       "0  18522  English  [welcom, superhero, news, sourc, latest, movi,...\n",
       "0  13989  English  [death, sex, amp, money, big, question, hard, ...\n",
       "0  18523  English  [snap, judgment, storytel, beat, mix, real, st...\n",
       "0  18524  English  [frontlin, present, audio, version, select, fu..."
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_no_web.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 3)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_no_web.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = corpora.MmCorpus('gensim/corpus.mm')\n",
    "dictionary = corpora.Dictionary.load('gensim/dictionary.dict')\n",
    "lsi = models.LsiModel.load('gensim/model.lsi')\n",
    "index = similarities.MatrixSimilarity.load('gensim/tfidf_lsi_similarities.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_corpus = [dictionary.doc2bow(text) for text in documents_no_web['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "old_corpus = list(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = old_corpus + new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6200"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform to tfidf\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "corpora.MmCorpus.serialize('gensim/corpus_tfidf.mm', corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 s, sys: 1.86 s, total: 29.8 s\n",
      "Wall time: 24.1 s\n"
     ]
    }
   ],
   "source": [
    "# lsi model on tfidf\n",
    "%time lsi = models.lsimodel.LsiModel(corpus_tfidf, num_topics = 100, id2word=dictionary)\n",
    "lsi.save('gensim/model.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    }
   ],
   "source": [
    "# calculate similarities\n",
    "index = similarities.MatrixSimilarity(lsi[corpus_tfidf])\n",
    "index.save('gensim/tfidf_lsi_similarities.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_mapping = pd.read_pickle('gensim/podcast_id_to_gensim_id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   podcast_id\n",
       "0       16392\n",
       "1       18489\n",
       "2       12350\n",
       "3       12351\n",
       "4       12352"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   podcast_id\n",
       "0       18521\n",
       "1       18522\n",
       "2       13989\n",
       "3       18523\n",
       "4       18524"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ids = pd.DataFrame({'podcast_id': podcastDf.podcast_id})\n",
    "new_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_mapping = pd.concat([id_mapping, new_ids], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_mapping.to_pickle('gensim/podcast_id_to_gensim_id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>16409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>12372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>16411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6170</th>\n",
       "      <td>15038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6171</th>\n",
       "      <td>18827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6172</th>\n",
       "      <td>18828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>18829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6174</th>\n",
       "      <td>17681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175</th>\n",
       "      <td>18830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176</th>\n",
       "      <td>18831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177</th>\n",
       "      <td>18832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6178</th>\n",
       "      <td>18833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179</th>\n",
       "      <td>18834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6180</th>\n",
       "      <td>18835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6181</th>\n",
       "      <td>18836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6182</th>\n",
       "      <td>18837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183</th>\n",
       "      <td>18838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184</th>\n",
       "      <td>18839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6185</th>\n",
       "      <td>18840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186</th>\n",
       "      <td>14506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6187</th>\n",
       "      <td>18429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>18841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6189</th>\n",
       "      <td>18842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6190</th>\n",
       "      <td>18843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>18844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>18845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193</th>\n",
       "      <td>18846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>18847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>18848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6196</th>\n",
       "      <td>18849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6197</th>\n",
       "      <td>18850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6198</th>\n",
       "      <td>18851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>18852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      podcast_id\n",
       "0          16392\n",
       "1          18489\n",
       "2          12350\n",
       "3          12351\n",
       "4          12352\n",
       "5          12355\n",
       "6          16396\n",
       "7          16399\n",
       "8          12357\n",
       "9          12359\n",
       "10         12361\n",
       "11         16403\n",
       "12         16404\n",
       "13         18490\n",
       "14         12363\n",
       "15         12365\n",
       "16         12366\n",
       "17         12385\n",
       "18         16409\n",
       "19         12369\n",
       "20         12370\n",
       "21         12371\n",
       "22         12372\n",
       "23         12373\n",
       "24         16411\n",
       "25         16426\n",
       "26         12375\n",
       "27         12376\n",
       "28         12377\n",
       "29         16429\n",
       "...          ...\n",
       "6170       15038\n",
       "6171       18827\n",
       "6172       18828\n",
       "6173       18829\n",
       "6174       17681\n",
       "6175       18830\n",
       "6176       18831\n",
       "6177       18832\n",
       "6178       18833\n",
       "6179       18834\n",
       "6180       18835\n",
       "6181       18836\n",
       "6182       18837\n",
       "6183       18838\n",
       "6184       18839\n",
       "6185       18840\n",
       "6186       14506\n",
       "6187       18429\n",
       "6188       18841\n",
       "6189       18842\n",
       "6190       18843\n",
       "6191       18844\n",
       "6192       18845\n",
       "6193       18846\n",
       "6194       18847\n",
       "6195       18848\n",
       "6196       18849\n",
       "6197       18850\n",
       "6198       18851\n",
       "6199       18852\n",
       "\n",
       "[6200 rows x 1 columns]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
