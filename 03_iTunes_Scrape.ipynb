{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycurl, json, sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from common_func import check_url\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "import urllib2\n",
    "import unidecode\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49930, 36)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkls = !ls pkl/itunes*COMPLETE.pkl\n",
    "podcastDf = pd.read_pickle(pkls[-1])\n",
    "podcastDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33227, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out podcasts with no itunes collection id\n",
    "podcastDf = podcastDf[np.isfinite(podcastDf['collectionId'])]\n",
    "podcastDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(6211, 36)"
=======
       "(6217, 36)"
>>>>>>> origin/master
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out podcasts without recent episodes\n",
    "days_thresh = 45\n",
    "thresh_date = dt.datetime.today() - dt.timedelta(days=days_thresh)\n",
    "\n",
    "podcastDf['releaseDate'] = pd.to_datetime(podcastDf['releaseDate'])\n",
    "podcastDf = podcastDf[podcastDf.releaseDate > thresh_date]\n",
    "podcastDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert collectionId to int\n",
    "podcastDf['collectionId'] = [int(x) for x in podcastDf['collectionId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sample for testing\n",
    "testDf = podcastDf.sample(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "baseUrl = 'https://itunes.apple.com/us/podcast/id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will store pycurl output\n",
    "class Test:\n",
    "   def __init__(self):\n",
    "       self.contents = ''\n",
    "\n",
    "   def body_callback(self, buf):\n",
    "       self.contents = self.contents + buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_curl(url):\n",
    "    t = Test()\n",
    "    c = pycurl.Curl()\n",
    "    c.setopt(pycurl.URL, url)\n",
    "    c.setopt(pycurl.HTTPHEADER, ['X-Apple-Store-Front: 143441-1,12', 'X-Apple-Tz: 3600'])\n",
    "    c.setopt(pycurl.USERAGENT, 'iTunes/9.2.1 (Macintosh; Intel Mac OS X 10.5.8) AppleWebKit/533.16')\n",
    "    c.setopt(pycurl.SSL_VERIFYHOST, 0)\n",
    "    c.setopt(pycurl.SSL_VERIFYPEER, 0)\n",
    "    c.setopt(pycurl.WRITEFUNCTION, t.body_callback)\n",
    "    c.perform()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_description(d):\n",
    "    d = unidecode.unidecode(d)\n",
    "    d = d.replace('\\n', ' ')\n",
    "    if re.findall(r'(.*) brought to you by.*', d):\n",
    "       d = re.sub(r'brought to you by.*', '', d)\n",
    "    if re.search(r'(.*) sponsored by.*', d):\n",
    "       d = re.sub(r'sponsored by.*', '', d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1147/6273 [1:03:01<15:24:29, 10.82s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-b7ad5246d9a9>\u001b[0m in \u001b[0;36mbody_callback\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mbody_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "error",
     "evalue": "(23, 'Failed writing body (0 != 16374)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-461-d07c39634d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# get podcast summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_curl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrapeUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-313-499ef3ff21b6>\u001b[0m in \u001b[0;36mrun_curl\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpycurl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_VERIFYPEER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpycurl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWRITEFUNCTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: (23, 'Failed writing body (0 != 16374)')"
     ]
    }
   ],
   "source": [
    "colNames = ['collectionId', 'podcastSummary', 'episodeNames', 'episodeDescriptions', 'alsoSubscribed']\n",
    "scrapeResults = pd.DataFrame(columns=colNames)\n",
    "\n",
    "for ind, row in tqdm.tqdm(podcastDf.iterrows(), total=podcastDf.shape[0]):\n",
    "    collectionId = row['collectionId']\n",
    "    scrapeUrl = baseUrl + str(collectionId)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        newUrl = newUrl[0]\n",
    "        newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "        try:\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle the current results\n",
    "scrapeResults['episodeDescriptions'] = [unicode(x) for x in scrapeResults['episodeDescriptions']]\n",
    "scrapeResults['episodeNames'] = [unicode(x) for x in scrapeResults['episodeNames']]\n",
    "scrapeResults['podcastSummary'] = [unicode(x) for x in scrapeResults['podcastSummary']]\n",
    "scrapeResults.to_pickle('pkl/scraped_podcasts_pt1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove already-retrieved values from podcastDf\n",
    "doneIds = scrapeResults['collectionId']\n",
    "\n",
    "subDf = podcastDf[~podcastDf.collectionId.isin(doneIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5126, 36)"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1124/5126 [1:12:16<3:08:46,  2.83s/it]//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ud83d' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\udcf1' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\udc4d' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude02' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude96' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\udcbe' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      " 25%|██▍       | 1261/5126 [1:29:46<2:30:56,  2.34s/it]//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude44' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      " 28%|██▊       | 1416/5126 [1:36:35<3:00:42,  2.92s/it]//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude09' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      " 29%|██▊       | 1466/5126 [1:38:47<3:01:09,  2.97s/it]"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-479-9095ec6464f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# redirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mnewUrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'https'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mnewUrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnewUrl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mnewUrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'&amp;'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mr'&'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for ind, row in tqdm.tqdm(subDf.iterrows(), total=subDf.shape[0]):\n",
    "    collectionId = row['collectionId']\n",
    "    scrapeUrl = baseUrl + str(collectionId)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        newUrl = newUrl[0]\n",
    "        newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "        try:\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle the current results\n",
    "scrapeResults['episodeDescriptions'] = [unicode(x) for x in scrapeResults['episodeDescriptions']]\n",
    "scrapeResults['episodeNames'] = [unicode(x) for x in scrapeResults['episodeNames']]\n",
    "scrapeResults['podcastSummary'] = [unicode(x) for x in scrapeResults['podcastSummary']]\n",
    "scrapeResults.to_pickle('pkl/scraped_podcasts_pt2.pkl')\n",
    "\n",
    "# remove already-retrieved values from podcastDf\n",
    "doneIds = scrapeResults['collectionId']\n",
    "\n",
    "subDf = podcastDf[~podcastDf.collectionId.isin(doneIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 832/3658 [1:01:17<2:41:33,  3.43s/it]"
     ]
    }
   ],
   "source": [
    "for ind, row in tqdm.tqdm(subDf.iterrows(), total=subDf.shape[0]):\n",
    "    collectionId = row['collectionId']\n",
    "    scrapeUrl = baseUrl + str(collectionId)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        try:\n",
    "            newUrl = newUrl[0]\n",
    "            newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrapeResults = pd.read_pickle('pkl/scraped_podcasts_pt2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove already-retrieved values from podcastDf\n",
    "doneIds = scrapeResults['collectionId']\n",
    "\n",
    "subDf = podcastDf[~podcastDf.collectionId.isin(doneIds)]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1448/3632 [1:14:58<1:37:47,  2.69s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-57d9a4fa772e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get podcast summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_curl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrapeUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smartQuotesTo'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTML_ENTITIES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isHTML'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m         \u001b[0mBeautifulStoneSoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     SELF_CLOSING_TAGS = buildTagMap(None,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, parseOnlyThese, fromEncoding, markupMassage, smartQuotesTo, convertEntities, selfClosingTags, isHTML)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkupMassage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkupMassage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misHTML\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misHTML\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopParsing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self, inDocumentEncoding, isHTML)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0mSGMLParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    136\u001b[0m                         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__starttag_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mfinish_starttag\u001b[0;34m(self, tag, attrs)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'do_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36munknown_starttag\u001b[0;34m(self, name, attrs, selfClosing)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentTag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, name, attrs, parent, previous)\u001b[0m\n\u001b[1;32m    560\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convertEntities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                                           val))\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m((k, val))\u001b[0m\n\u001b[1;32m    559\u001b[0m                                    re.sub(\"&(#\\d+|#x[0-9a-fA-F]+|\\w+);\",\n\u001b[1;32m    560\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convertEntities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m                                           val))\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(*key)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0m_MAXCACHE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;31m# internal: compile pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ind, row in tqdm.tqdm(subDf.iterrows(), total=subDf.shape[0]):\n",
    "    collectionId = row['collectionId']\n",
    "    scrapeUrl = baseUrl + str(collectionId)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        try:\n",
    "            newUrl = newUrl[0]\n",
    "            newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickle the current results\n",
    "scrapeResults['episodeDescriptions'] = [unicode(x) for x in scrapeResults['episodeDescriptions']]\n",
    "scrapeResults['episodeNames'] = [unicode(x) for x in scrapeResults['episodeNames']]\n",
    "scrapeResults['podcastSummary'] = [unicode(x) for x in scrapeResults['podcastSummary']]\n",
    "scrapeResults.to_pickle('pkl/scraped_podcasts_pt2.pkl')\n",
    "\n",
    "# remove already-retrieved values from podcastDf\n",
    "doneIds = scrapeResults['collectionId']\n",
    "\n",
    "subDf = podcastDf[~podcastDf.collectionId.isin(doneIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrapeResults = pd.read_pickle('pkl/scraped_podcasts_pt2.pkl')\n",
    "\n",
    "# remove already-retrieved values from podcastDf\n",
    "doneIds = scrapeResults['collectionId']\n",
    "\n",
    "subDf = podcastDf[~podcastDf.collectionId.isin(doneIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4061, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapeResults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2183, 36)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del(podcastDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 110/2183 [05:27<1:04:57,  1.88s/it]//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ud83d' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude09' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      " 16%|█▌        | 340/2183 [16:10<1:04:54,  2.11s/it]//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude1b' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      " 42%|████▏     | 926/2183 [49:12<1:54:53,  5.48s/it]//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\udc49' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\udc48' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      " 45%|████▌     | 983/2183 [56:17<41:57,  2.10s/it]//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude0d' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude18' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude4c' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\udc99' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\udc9a' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      " 48%|████▊     | 1041/2183 [58:41<1:21:15,  4.27s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b7ad5246d9a9>\u001b[0m in \u001b[0;36mbody_callback\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mbody_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "error",
     "evalue": "(23, 'Failed writing body (0 != 15365)')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-57d9a4fa772e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get podcast summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_curl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrapeUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-499ef3ff21b6>\u001b[0m in \u001b[0;36mrun_curl\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpycurl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_VERIFYPEER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpycurl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWRITEFUNCTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: (23, 'Failed writing body (0 != 15365)')"
     ]
    }
   ],
   "source": [
    "for ind, row in tqdm.tqdm(subDf.iterrows(), total=subDf.shape[0]):\n",
    "    collectionId = row['collectionId']\n",
    "    scrapeUrl = baseUrl + str(collectionId)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        try:\n",
    "            newUrl = newUrl[0]\n",
    "            newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrapeResults = pd.read_pickle('pkl/scraped_podcasts_pt3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove already-retrieved values from podcastDf\n",
    "doneIds = scrapeResults['collectionId']\n",
    "\n",
    "subDf = podcastDf[~podcastDf.collectionId.isin(doneIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1141, 36)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(podcastDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
=======
   "execution_count": null,
>>>>>>> origin/master
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      " 13%|█▎        | 152/1141 [07:58<50:35,  3.07s/it]//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ud83d' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      "//anaconda/lib/python2.7/site-packages/unidecode/__init__.py:50: RuntimeWarning: Surrogate character u'\\ude00' will be ignored. You might be using a narrow Python build.\n",
      "  return _unidecode(string)\n",
      " 88%|████████▊ | 1007/1141 [1:04:11<13:26,  6.02s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-57d9a4fa772e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get podcast summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_curl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscrapeUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smartQuotesTo'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTML_ENTITIES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isHTML'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m         \u001b[0mBeautifulStoneSoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m     SELF_CLOSING_TAGS = buildTagMap(None,\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, parseOnlyThese, fromEncoding, markupMassage, smartQuotesTo, convertEntities, selfClosingTags, isHTML)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkupMassage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarkupMassage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misHTML\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0misHTML\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopParsing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self, inDocumentEncoding, isHTML)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m         \u001b[0mSGMLParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    136\u001b[0m                         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__starttag_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/sgmllib.pyc\u001b[0m in \u001b[0;36mfinish_starttag\u001b[0;34m(self, tag, attrs)\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'do_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36munknown_starttag\u001b[0;34m(self, name, attrs, selfClosing)\u001b[0m\n\u001b[1;32m   1345\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m         \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentTag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parser, name, attrs, parent, previous)\u001b[0m\n\u001b[1;32m    560\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convertEntities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m                                           val))\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgetString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/BeautifulSoup.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;31m# Convert any HTML, XML, or numeric entities in the attribute values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m         convert = lambda(k, val): (k,\n\u001b[0m\u001b[1;32m    559\u001b[0m                                    re.sub(\"&(#\\d+|#x[0-9a-fA-F]+|\\w+);\",\n\u001b[1;32m    560\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convertEntities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
=======
      "  1%|          | 30/3632 [01:43<4:20:33,  4.34s/it]"
>>>>>>> origin/master
     ]
    }
   ],
   "source": [
    "for ind, row in tqdm.tqdm(subDf.iterrows(), total=subDf.shape[0]):\n",
    "    collectionId = row['collectionId']\n",
    "    scrapeUrl = baseUrl + str(collectionId)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        try:\n",
    "            newUrl = newUrl[0]\n",
    "            newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the current results\n",
    "scrapeResults['episodeDescriptions'] = [unicode(x) for x in scrapeResults['episodeDescriptions']]\n",
    "scrapeResults['episodeNames'] = [unicode(x) for x in scrapeResults['episodeNames']]\n",
    "scrapeResults['podcastSummary'] = [unicode(x) for x in scrapeResults['podcastSummary']]\n",
    "scrapeResults.to_pickle('pkl/scraped_podcasts_pt4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrapeResults = pd.read_pickle('pkl/scraped_podcasts_pt4.pkl')\n",
    "\n",
    "# remove already-retrieved values from podcastDf\n",
    "doneIds = scrapeResults['collectionId']\n",
    "\n",
    "subDf = podcastDf[~podcastDf.collectionId.isin(doneIds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 36)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for ind, row in tqdm.tqdm(subDf.iterrows(), total=subDf.shape[0]):\n",
    "    collectionId = row['collectionId']\n",
    "    scrapeUrl = baseUrl + str(collectionId)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        try:\n",
    "            newUrl = newUrl[0]\n",
    "            newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(collectionId),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the current results\n",
    "scrapeResults['episodeDescriptions'] = [unicode(x) for x in scrapeResults['episodeDescriptions']]\n",
    "scrapeResults['episodeNames'] = [unicode(x) for x in scrapeResults['episodeNames']]\n",
    "scrapeResults['podcastSummary'] = [unicode(x) for x in scrapeResults['podcastSummary']]\n",
    "scrapeResults.to_pickle('pkl/scraped_podcasts_COMPLETE.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6243, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapeResults.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alsoSubscribed</th>\n",
       "      <th>collectionId</th>\n",
       "      <th>episodeDescriptions</th>\n",
       "      <th>episodeNames</th>\n",
       "      <th>podcastSummary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[508647267, 544599736, 435853369, 515824283, 2...</td>\n",
       "      <td>515836681</td>\n",
       "      <td>['In this episode of \"A Cast of Kings,\" Joanna...</td>\n",
       "      <td>['A Cast of Kings S1E10 - Fire and Blood', 'A ...</td>\n",
       "      <td>A quasi-weekly discussion of the plots, themes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[272934484, 281295940, 191080586, 214143094, 2...</td>\n",
       "      <td>126723118</td>\n",
       "      <td>['Insurance news, interviews, rating announcem...</td>\n",
       "      <td>['BestDay - Friday, January 22, 2016', 'BestDa...</td>\n",
       "      <td>Insurance news, interviews, rating announcemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[491850770, 620439444, 943592978, 854521079, 3...</td>\n",
       "      <td>699748055</td>\n",
       "      <td>[\"They said they'd do it and they're following...</td>\n",
       "      <td>['Embrace the Spoilers: \"Star Wars: The Force ...</td>\n",
       "      <td>The Amove.tv crew talk video games, eSports, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[86237742, 213272283, 74411103, 89603501, 2712...</td>\n",
       "      <td>80693391</td>\n",
       "      <td>['Adultery is a very real danger to every marr...</td>\n",
       "      <td>['\"How to Divorce-Proof Your Marriage - II\"', ...</td>\n",
       "      <td>Pastor Greg Laurie's thirty-minute daily radio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[605155663, 662732734]</td>\n",
       "      <td>579605641</td>\n",
       "      <td>['hai, toiukotode, Jin Hui de10Hui Mu noHeng L...</td>\n",
       "      <td>['yuku2015Nian kuru2016Nian ~ He Zheng ', 'ari...</td>\n",
       "      <td>好きな事を、好きな音楽と共に、世界中のみんなとシェアして、世界中のいろんな人たちとつながって...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[251507798, 286889904, 559788668, 445221220, 3...</td>\n",
       "      <td>260190086</td>\n",
       "      <td>nan</td>\n",
       "      <td>['A State of Trance Official Podcast Episode 4...</td>\n",
       "      <td>Every week, Armin selects his favourite tunes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[260130529, 205205526, 454672565, 442159221, 5...</td>\n",
       "      <td>272223032</td>\n",
       "      <td>['Episode Overview -Episode #149 explores the ...</td>\n",
       "      <td>['Episode #149: Designing Awesome Experiences'...</td>\n",
       "      <td>Assistive Technology: Tools in Public Schools-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[500673866, 164829166, 173429229, 74362633, 28...</td>\n",
       "      <td>121493640</td>\n",
       "      <td>['This week on \"A Way with Words\": \\'Tis the s...</td>\n",
       "      <td>['Buckle Down (Rebroadcast) - 18 January 2016'...</td>\n",
       "      <td>A Way with Words is a fun and funny public rad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[397982286, 309821359, 296246178, 298321094, 1...</td>\n",
       "      <td>529175048</td>\n",
       "      <td>[\"Steve Forbes is CEO and Editor-in-Chief of F...</td>\n",
       "      <td>['Interview With Steve Forbes and A.F. Branco'...</td>\n",
       "      <td>African-American Conservatives focuses on topi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>895543727</td>\n",
       "      <td>nan</td>\n",
       "      <td>['AARON BARON SHOW 15 #TBT', 'AARON BARON SHOW...</td>\n",
       "      <td>Aaron Lead and Baron Massilia are both DJs and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[577553968, 81210923, 214089682, 354668519, 27...</td>\n",
       "      <td>495257235</td>\n",
       "      <td>[\"- Bill Brownstein, Montreal Gazette. - Russ ...</td>\n",
       "      <td>[\"Angelil funeral, O'Leary &amp; more. JAN 22.\", \"...</td>\n",
       "      <td>Take all the most important news that matters ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[486761654, 422037667, 73330895, 917918570, 20...</td>\n",
       "      <td>794399080</td>\n",
       "      <td>['Thomas Kilroy: playwright. by AbbeyTheatre',...</td>\n",
       "      <td>['Thomas Kilroy: playwright.', 'Abbey Talks Se...</td>\n",
       "      <td>The Abbey Theatre’s founders W.B. Yeats and La...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>296492282</td>\n",
       "      <td>nan</td>\n",
       "      <td>['All in All Together: Unstoppable Force of Un...</td>\n",
       "      <td>Welcome to the Abbott Loop Community Church po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[395151626, 209991975, 425179503, 135067274]</td>\n",
       "      <td>395151057</td>\n",
       "      <td>nan</td>\n",
       "      <td>['January 24 Audio Forecast - Afternoon Editio...</td>\n",
       "      <td>An audio only forecast from James Spann and th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[993284374, 387552110, 917770142, 804433138, 6...</td>\n",
       "      <td>956628068</td>\n",
       "      <td>[\"Books We Talk About:  Trigger Warning - Neil...</td>\n",
       "      <td>['Guest Host - Kim DeNero-Ackroyd, Short Stori...</td>\n",
       "      <td>Beth and Cari, who work in public libraries, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[554476563, 465219244, 600333075, 351089755, 3...</td>\n",
       "      <td>563781087</td>\n",
       "      <td>[\"Here's a different way to chill, especially ...</td>\n",
       "      <td>['RESIST. \"The Morning After\"', 'ABEL - URGE @...</td>\n",
       "      <td>House, Vocal house, Tribal House, Techno, Tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>657239453</td>\n",
       "      <td>nan</td>\n",
       "      <td>['No Favouritism (James 2:1-11)', 'Ruth (Part ...</td>\n",
       "      <td>Abergavenny Baptist Church \\n\\nBuilding Faith ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>573948470</td>\n",
       "      <td>nan</td>\n",
       "      <td>['1.17.16 Sermon', '1.17.16 Sermon pt 2', '1.1...</td>\n",
       "      <td>Weekly Messages from Abiding Harvest UMC in Br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[317204831, 390278738, 271206562, 110916650, 8...</td>\n",
       "      <td>375149712</td>\n",
       "      <td>['Program for 01/21/16 SAS Devotions:  Genesis...</td>\n",
       "      <td>['SAS Devotions:  Genesis 12:10-13:18', 'SAS D...</td>\n",
       "      <td>Whether interviewing guests about current even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>386539838</td>\n",
       "      <td>['Baptism of Our Lord Sermon by Pastor Jeffrey...</td>\n",
       "      <td>['Sermon for January 10, 2016', 'Sermon for De...</td>\n",
       "      <td>Sermons from Abiding Presence Lutheran Church,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[657393060, 431258766, 698012079, 564947362, 9...</td>\n",
       "      <td>657005891</td>\n",
       "      <td>['Something terrible has happened, but we must...</td>\n",
       "      <td>['Episode 124: SOS', 'The R-Zone Zone: Episode...</td>\n",
       "      <td>A bad games podcast hosted by Gary Butterfield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>840347063</td>\n",
       "      <td>[\"With the completion of the Metal Gear diarie...</td>\n",
       "      <td>['Abnormal Mapping 40 - Brother!!!', \"Abnormal...</td>\n",
       "      <td>Abnormal Mapping is the video game nightmare o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[480486345, 360084272, 329875043, 278981407]</td>\n",
       "      <td>302013762</td>\n",
       "      <td>[\"The Liquid Sunshine Podcast posse proudly pr...</td>\n",
       "      <td>['Liquid Sunshine: Episode 27 - The Liquid Sun...</td>\n",
       "      <td>AbortCast: Our Exclusive Interview Podcasts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>306133017</td>\n",
       "      <td>['Andrew and Keith are just a couple of guys w...</td>\n",
       "      <td>[\"Give It A Shot - Angel's Envy Bourbon Finish...</td>\n",
       "      <td>Andrew and Keith are just a couple of guys who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[286889904, 260190086, 251507798]</td>\n",
       "      <td>882873795</td>\n",
       "      <td>nan</td>\n",
       "      <td>['The Response to Our Salvation, Part II', 'Th...</td>\n",
       "      <td>Above and Beyond Ministries, and Immanuel Bapt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[311000883, 310881451, 414133397, 313091687, 4...</td>\n",
       "      <td>413632322</td>\n",
       "      <td>['20 Proverbs 18-19; 04 Numbers 13-17; 19 Psal...</td>\n",
       "      <td>['Day 24: 20 Proverbs 18-19; 04 Numbers 13-17;...</td>\n",
       "      <td>Listen through the King James Bible four times...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[311000883, 413632322, 313091687, 413624689, 3...</td>\n",
       "      <td>414133397</td>\n",
       "      <td>['Exodus 19-21', 'Exodus 16-18', 'Exodus 13-15...</td>\n",
       "      <td>['Day 24: Exodus 19-21', 'Day 23: Exodus 16-18...</td>\n",
       "      <td>Listen through the King James Bible in a year....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[412444164, 422413691, 349355470, 111065122]</td>\n",
       "      <td>348891830</td>\n",
       "      <td>['Mtt 27', 'Mtt 26', 'Mtt 25', 'Mtt 24', 'Mtt ...</td>\n",
       "      <td>['Day 24: Mtt 27', 'Day 23: Mtt 26', 'Day 21: ...</td>\n",
       "      <td>Listen through the Mandarin Chinese New Testam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>274771117</td>\n",
       "      <td>[\"ABQ Connect is Albuquerque's live, local tal...</td>\n",
       "      <td>['1/22/2016 ABQ Connect', '1/21/2016 ABQ Conne...</td>\n",
       "      <td>ABQ Connect is Albuquerque's live, local talk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[622330884, 633364602, 938410733, 960044599, 7...</td>\n",
       "      <td>796618604</td>\n",
       "      <td>nan</td>\n",
       "      <td>['AP 106 - The Good and the Bad Deals', \"AP 10...</td>\n",
       "      <td>The Abroaders Podcast is about leveraging inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[513748183, 441232694, 420200438, 642632314, 6...</td>\n",
       "      <td>73900363</td>\n",
       "      <td>['YSDC Super Screen 2, Sedefkar Simulacrum, ca...</td>\n",
       "      <td>['Cthulhu Breakfast Club: Jumping the Sharktop...</td>\n",
       "      <td>Devoted to Lovecraftian games &amp;amp; media, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>649744991</td>\n",
       "      <td>['MES in 5: Studying a Cadaver  - Dec 26, 2015...</td>\n",
       "      <td>['MES in 5: Studying a Cadaver', 'MES in 5: St...</td>\n",
       "      <td>YUTORAH: YU Student Medical Ethics Society -- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[524230919, 207778880]</td>\n",
       "      <td>380118647</td>\n",
       "      <td>[\"On this week's Z Report LIVE we have a truly...</td>\n",
       "      <td>['Z Report Live! Show #282', 'Z Report Live! S...</td>\n",
       "      <td>Jewish music aficionados will immediately reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>393171775</td>\n",
       "      <td>['Music from local artists Ahoy Matey!! Give m...</td>\n",
       "      <td>['Z107.7 FM Local Music Showcase hosted by Pat...</td>\n",
       "      <td>Did you know the Morongo Basin is full of tale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>331453358</td>\n",
       "      <td>nan</td>\n",
       "      <td>['Galatians 3:6-29', 'Galatians 3:1-5', 'Galat...</td>\n",
       "      <td>This is the audio podcast featuring Pastor Zac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>385109592</td>\n",
       "      <td>['\"I assist ambitious and heart-centered entre...</td>\n",
       "      <td>['Open Forum - Why you should become an Africa...</td>\n",
       "      <td>Zambia BlogTalkRadio's goal is  to reach Zambi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[121173183, 121165910, 280255546, 337000848, 2...</td>\n",
       "      <td>271786832</td>\n",
       "      <td>[\"01. 2Night &amp; 2907 - Do it Like This 02. Stil...</td>\n",
       "      <td>['Zemixx 534, Boomers Alert !!!', 'Zemixx 533,...</td>\n",
       "      <td>ZeMIXX every week, 60 minutes of the hottest h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[212188040, 626338579, 280255546, 337000848, 2...</td>\n",
       "      <td>121165910</td>\n",
       "      <td>[\"01. 2Night &amp; 2907 - Do it Like This 02. Stil...</td>\n",
       "      <td>['Zemixx 534, Boomers Alert !!!', 'Zemixx 533,...</td>\n",
       "      <td>ZeMIXX, chaque semaine c'est 60 minutes de nou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[468163646, 590542998, 302754403, 633838225, 3...</td>\n",
       "      <td>128594474</td>\n",
       "      <td>[\"Our resident tiki bar psychic hasn't dropped...</td>\n",
       "      <td>['347 Campari + Kraken = Psychic Adventures', ...</td>\n",
       "      <td>Aloha, welcome to the Zen Tiki Lounge podcast....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>422532185</td>\n",
       "      <td>[\"Everyone has lapses in judgment and moral fa...</td>\n",
       "      <td>['Acceptable Carnality: Why behavioral account...</td>\n",
       "      <td>Faith. Race. Politics. Education. Global Issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>878554955</td>\n",
       "      <td>['Four comedians.  One bottle of whiskey.  Way...</td>\n",
       "      <td>['014: The Whiskey Awakens', '013: Obligatory ...</td>\n",
       "      <td>The podcast of wheelchair comedian Michael O'C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[713066884, 561769983, 756151885, 539379485, 4...</td>\n",
       "      <td>878811084</td>\n",
       "      <td>['Here we are,THE YEAR OF THE MONKEES! The Zil...</td>\n",
       "      <td>['Zilch #47 THE YEAR OF THE MONKEES!', 'Zilch ...</td>\n",
       "      <td>Zilch!:A Monkees Podcast!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>789762074</td>\n",
       "      <td>nan</td>\n",
       "      <td>['January 24, 2016-\"But, What about me?\"', 'Ja...</td>\n",
       "      <td>Sermons delivered by Rev. Craig Nehring, NALC ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>516951844</td>\n",
       "      <td>['What Christian Friend Would You Call at 3am'...</td>\n",
       "      <td>['What Christian Friend Would You Call at 3am'...</td>\n",
       "      <td>Zion's Church\\n770 Zion's Church Rd.\\nHamburg,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>220058832</td>\n",
       "      <td>[\"Trial of Jimmy Lee Hardy for apostasy. For d...</td>\n",
       "      <td>['Trial of Jimmy Hardy for Apostasy', 'Trial o...</td>\n",
       "      <td>For he taught them as one having authority, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>348824219</td>\n",
       "      <td>['Jesus, Your Savior Of Body And Soul / Luke 4...</td>\n",
       "      <td>['January 24, 2016 Jesus, Your Savior Of Body ...</td>\n",
       "      <td>ZionSchumm.org Proclaiming a Changeless Christ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>348824357</td>\n",
       "      <td>['Nehemiah 8:1-3, 5-6, 8-10 / 1 Corinthians 12...</td>\n",
       "      <td>['January 24, 2016 Scripture', 'January 17, 20...</td>\n",
       "      <td>ZionSchumm.org Proclaiming a Changeless Christ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[509969970, 871109161, 870912090, 797926884, 2...</td>\n",
       "      <td>488810869</td>\n",
       "      <td>nan</td>\n",
       "      <td>['Listen: Guy &amp; Georgia Catch Up With Chloe Gr...</td>\n",
       "      <td>Get the latest from ZM's Sealed Section - than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>372942863</td>\n",
       "      <td>nan</td>\n",
       "      <td>['Epiphany: Flipping the Switch Pt. 3', 'Epiph...</td>\n",
       "      <td>Zoar Baptist Church, Shelby, NC - Podcast upda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[664663777, 491990698, 874199654, 88976734, 10...</td>\n",
       "      <td>886045028</td>\n",
       "      <td>[\"It's been 6 whole months since my episode de...</td>\n",
       "      <td>['Love &amp; Radio: The Adventures of Zoe Nighting...</td>\n",
       "      <td>You're Welcome is a satirical improv comedy sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[74845990, 410230780, 602793261, 206197047, 26...</td>\n",
       "      <td>216328919</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Our weekly national television program \"Zola L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[492647899, 370871012, 665968158, 341335411, 5...</td>\n",
       "      <td>652149995</td>\n",
       "      <td>[\"This week we dive into TONS O' STUFF! A fair...</td>\n",
       "      <td>['CRAWL OR DIE', 'DESOLATION MANOR WITH RED RU...</td>\n",
       "      <td>FROM THE ASHES OF A WORLD OVER RUN BY ZOMBIES,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[526614430, 595841454, 272188851, 397891265, 4...</td>\n",
       "      <td>319868584</td>\n",
       "      <td>[\"Scotto and Uncle John discuss the latest ins...</td>\n",
       "      <td>['Zombie Take-Out Episode 267B: Siblinghood of...</td>\n",
       "      <td>Zombie Take-Out is a podcast about B/cult movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[119375461, 681573634, 129404020, 509870584, 3...</td>\n",
       "      <td>562755631</td>\n",
       "      <td>[\"Ryan and Lou hold down the zombie proof fort...</td>\n",
       "      <td>['ZAMP 126 - The Lovely Death Road', 'ZAMP 125...</td>\n",
       "      <td>Join Bob, Rick, Ryan and Lou as they prepare y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>863059491</td>\n",
       "      <td>['House/Progressive House: 1.Amtrac - Darkest ...</td>\n",
       "      <td>['Zomby Dance Radio Show (Episode #087)', 'Zom...</td>\n",
       "      <td>Zomby Dance Radio Show  \\n \\nZOMBY CATZ The ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>542913446</td>\n",
       "      <td>[\"A lot of celebrities are dying to cancer, an...</td>\n",
       "      <td>['Episode 152: Rhythm_eBooks', \"Episode 151: I...</td>\n",
       "      <td>The Echo Chamber is a music podcast that is al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[422049570, 337000848, 120107389]</td>\n",
       "      <td>416671394</td>\n",
       "      <td>['Mix by Adolphe resident dj @Blockhaus belgiu...</td>\n",
       "      <td>['\"A\" MIND DESTROYER', 'blockhaus Mix 1 (openi...</td>\n",
       "      <td>ZOOclub innovates and presents    :    Blockha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[155963493, 419458838, 354650652, 536781652, 5...</td>\n",
       "      <td>330322710</td>\n",
       "      <td>['PART ONE - A PROPHETS VIEW OF THE NEW YEAR R...</td>\n",
       "      <td>['The Conspiracy Show Podcast - January 17th',...</td>\n",
       "      <td>The Best of The Best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[274455249, 378335669, 200778765, 474005304, 3...</td>\n",
       "      <td>343591416</td>\n",
       "      <td>['Tune into the latest episode of The Garden S...</td>\n",
       "      <td>['The Garden Show Podcast - January 16th', 'Th...</td>\n",
       "      <td>The Best of The Best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[330322710]</td>\n",
       "      <td>481388439</td>\n",
       "      <td>[\"Jane Brown fills in for Libby Znaimer.  Acco...</td>\n",
       "      <td>['Zoomer Week in Review Podcast - January 17th...</td>\n",
       "      <td>The Best of The Best</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6243 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       alsoSubscribed  collectionId  \\\n",
       "0   [508647267, 544599736, 435853369, 515824283, 2...     515836681   \n",
       "0   [272934484, 281295940, 191080586, 214143094, 2...     126723118   \n",
       "0   [491850770, 620439444, 943592978, 854521079, 3...     699748055   \n",
       "0   [86237742, 213272283, 74411103, 89603501, 2712...      80693391   \n",
       "0                              [605155663, 662732734]     579605641   \n",
       "0   [251507798, 286889904, 559788668, 445221220, 3...     260190086   \n",
       "0   [260130529, 205205526, 454672565, 442159221, 5...     272223032   \n",
       "0   [500673866, 164829166, 173429229, 74362633, 28...     121493640   \n",
       "0   [397982286, 309821359, 296246178, 298321094, 1...     529175048   \n",
       "0                                                  []     895543727   \n",
       "0   [577553968, 81210923, 214089682, 354668519, 27...     495257235   \n",
       "0   [486761654, 422037667, 73330895, 917918570, 20...     794399080   \n",
       "0                                                  []     296492282   \n",
       "0        [395151626, 209991975, 425179503, 135067274]     395151057   \n",
       "0   [993284374, 387552110, 917770142, 804433138, 6...     956628068   \n",
       "0   [554476563, 465219244, 600333075, 351089755, 3...     563781087   \n",
       "0                                                  []     657239453   \n",
       "0                                                  []     573948470   \n",
       "0   [317204831, 390278738, 271206562, 110916650, 8...     375149712   \n",
       "0                                                  []     386539838   \n",
       "0   [657393060, 431258766, 698012079, 564947362, 9...     657005891   \n",
       "0                                                  []     840347063   \n",
       "0        [480486345, 360084272, 329875043, 278981407]     302013762   \n",
       "0                                                  []     306133017   \n",
       "0                   [286889904, 260190086, 251507798]     882873795   \n",
       "0   [311000883, 310881451, 414133397, 313091687, 4...     413632322   \n",
       "0   [311000883, 413632322, 313091687, 413624689, 3...     414133397   \n",
       "0        [412444164, 422413691, 349355470, 111065122]     348891830   \n",
       "0                                                  []     274771117   \n",
       "0   [622330884, 633364602, 938410733, 960044599, 7...     796618604   \n",
       "..                                                ...           ...   \n",
       "0   [513748183, 441232694, 420200438, 642632314, 6...      73900363   \n",
       "0                                                  []     649744991   \n",
       "0                              [524230919, 207778880]     380118647   \n",
       "0                                                  []     393171775   \n",
       "0                                                  []     331453358   \n",
       "0                                                  []     385109592   \n",
       "0   [121173183, 121165910, 280255546, 337000848, 2...     271786832   \n",
       "0   [212188040, 626338579, 280255546, 337000848, 2...     121165910   \n",
       "0   [468163646, 590542998, 302754403, 633838225, 3...     128594474   \n",
       "0                                                  []     422532185   \n",
       "0                                                  []     878554955   \n",
       "0   [713066884, 561769983, 756151885, 539379485, 4...     878811084   \n",
       "0                                                  []     789762074   \n",
       "0                                                  []     516951844   \n",
       "0                                                  []     220058832   \n",
       "0                                                  []     348824219   \n",
       "0                                                  []     348824357   \n",
       "0   [509969970, 871109161, 870912090, 797926884, 2...     488810869   \n",
       "0                                                  []     372942863   \n",
       "0   [664663777, 491990698, 874199654, 88976734, 10...     886045028   \n",
       "0   [74845990, 410230780, 602793261, 206197047, 26...     216328919   \n",
       "0   [492647899, 370871012, 665968158, 341335411, 5...     652149995   \n",
       "0   [526614430, 595841454, 272188851, 397891265, 4...     319868584   \n",
       "0   [119375461, 681573634, 129404020, 509870584, 3...     562755631   \n",
       "0                                                  []     863059491   \n",
       "0                                                  []     542913446   \n",
       "0                   [422049570, 337000848, 120107389]     416671394   \n",
       "0   [155963493, 419458838, 354650652, 536781652, 5...     330322710   \n",
       "0   [274455249, 378335669, 200778765, 474005304, 3...     343591416   \n",
       "0                                         [330322710]     481388439   \n",
       "\n",
       "                                  episodeDescriptions  \\\n",
       "0   ['In this episode of \"A Cast of Kings,\" Joanna...   \n",
       "0   ['Insurance news, interviews, rating announcem...   \n",
       "0   [\"They said they'd do it and they're following...   \n",
       "0   ['Adultery is a very real danger to every marr...   \n",
       "0   ['hai, toiukotode, Jin Hui de10Hui Mu noHeng L...   \n",
       "0                                                 nan   \n",
       "0   ['Episode Overview -Episode #149 explores the ...   \n",
       "0   ['This week on \"A Way with Words\": \\'Tis the s...   \n",
       "0   [\"Steve Forbes is CEO and Editor-in-Chief of F...   \n",
       "0                                                 nan   \n",
       "0   [\"- Bill Brownstein, Montreal Gazette. - Russ ...   \n",
       "0   ['Thomas Kilroy: playwright. by AbbeyTheatre',...   \n",
       "0                                                 nan   \n",
       "0                                                 nan   \n",
       "0   [\"Books We Talk About:  Trigger Warning - Neil...   \n",
       "0   [\"Here's a different way to chill, especially ...   \n",
       "0                                                 nan   \n",
       "0                                                 nan   \n",
       "0   ['Program for 01/21/16 SAS Devotions:  Genesis...   \n",
       "0   ['Baptism of Our Lord Sermon by Pastor Jeffrey...   \n",
       "0   ['Something terrible has happened, but we must...   \n",
       "0   [\"With the completion of the Metal Gear diarie...   \n",
       "0   [\"The Liquid Sunshine Podcast posse proudly pr...   \n",
       "0   ['Andrew and Keith are just a couple of guys w...   \n",
       "0                                                 nan   \n",
       "0   ['20 Proverbs 18-19; 04 Numbers 13-17; 19 Psal...   \n",
       "0   ['Exodus 19-21', 'Exodus 16-18', 'Exodus 13-15...   \n",
       "0   ['Mtt 27', 'Mtt 26', 'Mtt 25', 'Mtt 24', 'Mtt ...   \n",
       "0   [\"ABQ Connect is Albuquerque's live, local tal...   \n",
       "0                                                 nan   \n",
       "..                                                ...   \n",
       "0   ['YSDC Super Screen 2, Sedefkar Simulacrum, ca...   \n",
       "0   ['MES in 5: Studying a Cadaver  - Dec 26, 2015...   \n",
       "0   [\"On this week's Z Report LIVE we have a truly...   \n",
       "0   ['Music from local artists Ahoy Matey!! Give m...   \n",
       "0                                                 nan   \n",
       "0   ['\"I assist ambitious and heart-centered entre...   \n",
       "0   [\"01. 2Night & 2907 - Do it Like This 02. Stil...   \n",
       "0   [\"01. 2Night & 2907 - Do it Like This 02. Stil...   \n",
       "0   [\"Our resident tiki bar psychic hasn't dropped...   \n",
       "0   [\"Everyone has lapses in judgment and moral fa...   \n",
       "0   ['Four comedians.  One bottle of whiskey.  Way...   \n",
       "0   ['Here we are,THE YEAR OF THE MONKEES! The Zil...   \n",
       "0                                                 nan   \n",
       "0   ['What Christian Friend Would You Call at 3am'...   \n",
       "0   [\"Trial of Jimmy Lee Hardy for apostasy. For d...   \n",
       "0   ['Jesus, Your Savior Of Body And Soul / Luke 4...   \n",
       "0   ['Nehemiah 8:1-3, 5-6, 8-10 / 1 Corinthians 12...   \n",
       "0                                                 nan   \n",
       "0                                                 nan   \n",
       "0   [\"It's been 6 whole months since my episode de...   \n",
       "0                                                  []   \n",
       "0   [\"This week we dive into TONS O' STUFF! A fair...   \n",
       "0   [\"Scotto and Uncle John discuss the latest ins...   \n",
       "0   [\"Ryan and Lou hold down the zombie proof fort...   \n",
       "0   ['House/Progressive House: 1.Amtrac - Darkest ...   \n",
       "0   [\"A lot of celebrities are dying to cancer, an...   \n",
       "0   ['Mix by Adolphe resident dj @Blockhaus belgiu...   \n",
       "0   ['PART ONE - A PROPHETS VIEW OF THE NEW YEAR R...   \n",
       "0   ['Tune into the latest episode of The Garden S...   \n",
       "0   [\"Jane Brown fills in for Libby Znaimer.  Acco...   \n",
       "\n",
       "                                         episodeNames  \\\n",
       "0   ['A Cast of Kings S1E10 - Fire and Blood', 'A ...   \n",
       "0   ['BestDay - Friday, January 22, 2016', 'BestDa...   \n",
       "0   ['Embrace the Spoilers: \"Star Wars: The Force ...   \n",
       "0   ['\"How to Divorce-Proof Your Marriage - II\"', ...   \n",
       "0   ['yuku2015Nian kuru2016Nian ~ He Zheng ', 'ari...   \n",
       "0   ['A State of Trance Official Podcast Episode 4...   \n",
       "0   ['Episode #149: Designing Awesome Experiences'...   \n",
       "0   ['Buckle Down (Rebroadcast) - 18 January 2016'...   \n",
       "0   ['Interview With Steve Forbes and A.F. Branco'...   \n",
       "0   ['AARON BARON SHOW 15 #TBT', 'AARON BARON SHOW...   \n",
       "0   [\"Angelil funeral, O'Leary & more. JAN 22.\", \"...   \n",
       "0   ['Thomas Kilroy: playwright.', 'Abbey Talks Se...   \n",
       "0   ['All in All Together: Unstoppable Force of Un...   \n",
       "0   ['January 24 Audio Forecast - Afternoon Editio...   \n",
       "0   ['Guest Host - Kim DeNero-Ackroyd, Short Stori...   \n",
       "0   ['RESIST. \"The Morning After\"', 'ABEL - URGE @...   \n",
       "0   ['No Favouritism (James 2:1-11)', 'Ruth (Part ...   \n",
       "0   ['1.17.16 Sermon', '1.17.16 Sermon pt 2', '1.1...   \n",
       "0   ['SAS Devotions:  Genesis 12:10-13:18', 'SAS D...   \n",
       "0   ['Sermon for January 10, 2016', 'Sermon for De...   \n",
       "0   ['Episode 124: SOS', 'The R-Zone Zone: Episode...   \n",
       "0   ['Abnormal Mapping 40 - Brother!!!', \"Abnormal...   \n",
       "0   ['Liquid Sunshine: Episode 27 - The Liquid Sun...   \n",
       "0   [\"Give It A Shot - Angel's Envy Bourbon Finish...   \n",
       "0   ['The Response to Our Salvation, Part II', 'Th...   \n",
       "0   ['Day 24: 20 Proverbs 18-19; 04 Numbers 13-17;...   \n",
       "0   ['Day 24: Exodus 19-21', 'Day 23: Exodus 16-18...   \n",
       "0   ['Day 24: Mtt 27', 'Day 23: Mtt 26', 'Day 21: ...   \n",
       "0   ['1/22/2016 ABQ Connect', '1/21/2016 ABQ Conne...   \n",
       "0   ['AP 106 - The Good and the Bad Deals', \"AP 10...   \n",
       "..                                                ...   \n",
       "0   ['Cthulhu Breakfast Club: Jumping the Sharktop...   \n",
       "0   ['MES in 5: Studying a Cadaver', 'MES in 5: St...   \n",
       "0   ['Z Report Live! Show #282', 'Z Report Live! S...   \n",
       "0   ['Z107.7 FM Local Music Showcase hosted by Pat...   \n",
       "0   ['Galatians 3:6-29', 'Galatians 3:1-5', 'Galat...   \n",
       "0   ['Open Forum - Why you should become an Africa...   \n",
       "0   ['Zemixx 534, Boomers Alert !!!', 'Zemixx 533,...   \n",
       "0   ['Zemixx 534, Boomers Alert !!!', 'Zemixx 533,...   \n",
       "0   ['347 Campari + Kraken = Psychic Adventures', ...   \n",
       "0   ['Acceptable Carnality: Why behavioral account...   \n",
       "0   ['014: The Whiskey Awakens', '013: Obligatory ...   \n",
       "0   ['Zilch #47 THE YEAR OF THE MONKEES!', 'Zilch ...   \n",
       "0   ['January 24, 2016-\"But, What about me?\"', 'Ja...   \n",
       "0   ['What Christian Friend Would You Call at 3am'...   \n",
       "0   ['Trial of Jimmy Hardy for Apostasy', 'Trial o...   \n",
       "0   ['January 24, 2016 Jesus, Your Savior Of Body ...   \n",
       "0   ['January 24, 2016 Scripture', 'January 17, 20...   \n",
       "0   ['Listen: Guy & Georgia Catch Up With Chloe Gr...   \n",
       "0   ['Epiphany: Flipping the Switch Pt. 3', 'Epiph...   \n",
       "0   ['Love & Radio: The Adventures of Zoe Nighting...   \n",
       "0                                                  []   \n",
       "0   ['CRAWL OR DIE', 'DESOLATION MANOR WITH RED RU...   \n",
       "0   ['Zombie Take-Out Episode 267B: Siblinghood of...   \n",
       "0   ['ZAMP 126 - The Lovely Death Road', 'ZAMP 125...   \n",
       "0   ['Zomby Dance Radio Show (Episode #087)', 'Zom...   \n",
       "0   ['Episode 152: Rhythm_eBooks', \"Episode 151: I...   \n",
       "0   ['\"A\" MIND DESTROYER', 'blockhaus Mix 1 (openi...   \n",
       "0   ['The Conspiracy Show Podcast - January 17th',...   \n",
       "0   ['The Garden Show Podcast - January 16th', 'Th...   \n",
       "0   ['Zoomer Week in Review Podcast - January 17th...   \n",
       "\n",
       "                                       podcastSummary  \n",
       "0   A quasi-weekly discussion of the plots, themes...  \n",
       "0   Insurance news, interviews, rating announcemen...  \n",
       "0   The Amove.tv crew talk video games, eSports, a...  \n",
       "0   Pastor Greg Laurie's thirty-minute daily radio...  \n",
       "0   好きな事を、好きな音楽と共に、世界中のみんなとシェアして、世界中のいろんな人たちとつながって...  \n",
       "0   Every week, Armin selects his favourite tunes ...  \n",
       "0   Assistive Technology: Tools in Public Schools-...  \n",
       "0   A Way with Words is a fun and funny public rad...  \n",
       "0   African-American Conservatives focuses on topi...  \n",
       "0   Aaron Lead and Baron Massilia are both DJs and...  \n",
       "0   Take all the most important news that matters ...  \n",
       "0   The Abbey Theatre’s founders W.B. Yeats and La...  \n",
       "0   Welcome to the Abbott Loop Community Church po...  \n",
       "0   An audio only forecast from James Spann and th...  \n",
       "0   Beth and Cari, who work in public libraries, c...  \n",
       "0   House, Vocal house, Tribal House, Techno, Tech...  \n",
       "0   Abergavenny Baptist Church \\n\\nBuilding Faith ...  \n",
       "0   Weekly Messages from Abiding Harvest UMC in Br...  \n",
       "0   Whether interviewing guests about current even...  \n",
       "0   Sermons from Abiding Presence Lutheran Church,...  \n",
       "0   A bad games podcast hosted by Gary Butterfield...  \n",
       "0   Abnormal Mapping is the video game nightmare o...  \n",
       "0         AbortCast: Our Exclusive Interview Podcasts  \n",
       "0   Andrew and Keith are just a couple of guys who...  \n",
       "0   Above and Beyond Ministries, and Immanuel Bapt...  \n",
       "0   Listen through the King James Bible four times...  \n",
       "0   Listen through the King James Bible in a year....  \n",
       "0   Listen through the Mandarin Chinese New Testam...  \n",
       "0   ABQ Connect is Albuquerque's live, local talk ...  \n",
       "0   The Abroaders Podcast is about leveraging inte...  \n",
       "..                                                ...  \n",
       "0   Devoted to Lovecraftian games &amp; media, the...  \n",
       "0   YUTORAH: YU Student Medical Ethics Society -- ...  \n",
       "0   Jewish music aficionados will immediately reco...  \n",
       "0   Did you know the Morongo Basin is full of tale...  \n",
       "0   This is the audio podcast featuring Pastor Zac...  \n",
       "0   Zambia BlogTalkRadio's goal is  to reach Zambi...  \n",
       "0   ZeMIXX every week, 60 minutes of the hottest h...  \n",
       "0   ZeMIXX, chaque semaine c'est 60 minutes de nou...  \n",
       "0   Aloha, welcome to the Zen Tiki Lounge podcast....  \n",
       "0   Faith. Race. Politics. Education. Global Issue...  \n",
       "0   The podcast of wheelchair comedian Michael O'C...  \n",
       "0                           Zilch!:A Monkees Podcast!  \n",
       "0   Sermons delivered by Rev. Craig Nehring, NALC ...  \n",
       "0   Zion's Church\\n770 Zion's Church Rd.\\nHamburg,...  \n",
       "0   For he taught them as one having authority, an...  \n",
       "0   ZionSchumm.org Proclaiming a Changeless Christ...  \n",
       "0   ZionSchumm.org Proclaiming a Changeless Christ...  \n",
       "0   Get the latest from ZM's Sealed Section - than...  \n",
       "0   Zoar Baptist Church, Shelby, NC - Podcast upda...  \n",
       "0   You're Welcome is a satirical improv comedy sh...  \n",
       "0   Our weekly national television program \"Zola L...  \n",
       "0   FROM THE ASHES OF A WORLD OVER RUN BY ZOMBIES,...  \n",
       "0   Zombie Take-Out is a podcast about B/cult movi...  \n",
       "0   Join Bob, Rick, Ryan and Lou as they prepare y...  \n",
       "0   Zomby Dance Radio Show  \\n \\nZOMBY CATZ The ma...  \n",
       "0   The Echo Chamber is a music podcast that is al...  \n",
       "0   ZOOclub innovates and presents    :    Blockha...  \n",
       "0                                The Best of The Best  \n",
       "0                                The Best of The Best  \n",
       "0                                The Best of The Best  \n",
       "\n",
       "[6243 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrapeResults"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> origin/master
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
